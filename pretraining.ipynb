{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torch.utils.data import DataLoader\n",
        "import wandb"
      ],
      "metadata": {
        "id": "O1bTrBylBwlL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"cifar10-training\", config={\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 64,\n",
        "    \"learning_rate\": 0.001,\n",
        "    \"dataset\": \"CIFAR-10\",\n",
        "    \"architecture\": \"ResNet18\",\n",
        "})\n",
        "config = wandb.config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "nhAAUF8TBxoJ",
        "outputId": "6330c6af-d78e-4e3c-c4d9-ed45d17ea00e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:mrlin8xd) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁█</td></tr><tr><td>train_loss</td><td>█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2</td></tr><tr><td>train_loss</td><td>0.43964</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">trim-spaceship-3</strong> at: <a href='https://wandb.ai/ramusdmitry-hse-university/cifar_pretraining/runs/mrlin8xd' target=\"_blank\">https://wandb.ai/ramusdmitry-hse-university/cifar_pretraining/runs/mrlin8xd</a><br/> View project at: <a href='https://wandb.ai/ramusdmitry-hse-university/cifar_pretraining' target=\"_blank\">https://wandb.ai/ramusdmitry-hse-university/cifar_pretraining</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241117_212425-mrlin8xd/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:mrlin8xd). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241117_212954-y20w6gd6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/ramusdmitry-hse-university/cifar10-training/runs/y20w6gd6' target=\"_blank\">valiant-rain-1</a></strong> to <a href='https://wandb.ai/ramusdmitry-hse-university/cifar10-training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/ramusdmitry-hse-university/cifar10-training' target=\"_blank\">https://wandb.ai/ramusdmitry-hse-university/cifar10-training</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/ramusdmitry-hse-university/cifar10-training/runs/y20w6gd6' target=\"_blank\">https://wandb.ai/ramusdmitry-hse-university/cifar10-training/runs/y20w6gd6</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # add mps for apple"
      ],
      "metadata": {
        "id": "kCH5UB-CBy6r"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Аугментации данных\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),  # Рандомное обрезание\n",
        "    transforms.RandomHorizontalFlip(),     # Горизонтальное отражение\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))  # Нормализация\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])"
      ],
      "metadata": {
        "id": "b8M4l3a5B2Hm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка CIFAR-10\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKwvX4j6B3NJ",
        "outputId": "b9219201-4ac4-49e4-ac86-ac6012e867f4"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Используем ResNet18, предобученную на ImageNet\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Заменяем последний слой под количество классов CIFAR-10\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)  # CIFAR-10 имеет 10 классов\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tNuXuUXB5b4",
        "outputId": "b08ac3e1-9a06-4143-fbe7-479e79eec5b4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# оптимизатор\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=config.learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)  # Шаговое снижение learning rate"
      ],
      "metadata": {
        "id": "sbU6DMVMBvX3"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, dataloader, optimizer, criterion, scheduler, num_epochs):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "        accuracy = 100.0 * correct / total\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        scheduler.step()\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "        wandb.log({\"epoch\": epoch + 1, \"train_loss\": avg_loss, \"train_accuracy\": accuracy, \"lr\": scheduler.get_last_lr()[0]})\n",
        "\n",
        "def evaluate_model(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    accuracy = 100.0 * correct / total\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    print(f\"Test Loss: {avg_loss:.4f}, Test Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "    wandb.log({\"test_loss\": avg_loss, \"test_accuracy\": accuracy})"
      ],
      "metadata": {
        "id": "yJBhAgr6BlIF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, optimizer, criterion, scheduler, config.epochs)\n",
        "evaluate_model(model, test_loader, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcLAigbsBpmS",
        "outputId": "689bac75-1e4d-4e6c-9e9f-f1755d1f3a71"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.1149, Accuracy: 61.90%\n",
            "Epoch [2/10], Loss: 0.8248, Accuracy: 72.02%\n",
            "Epoch [3/10], Loss: 0.7180, Accuracy: 75.57%\n",
            "Epoch [4/10], Loss: 0.6547, Accuracy: 77.89%\n",
            "Epoch [5/10], Loss: 0.6142, Accuracy: 79.15%\n",
            "Epoch [6/10], Loss: 0.5013, Accuracy: 82.78%\n",
            "Epoch [7/10], Loss: 0.4612, Accuracy: 84.08%\n",
            "Epoch [8/10], Loss: 0.4434, Accuracy: 84.86%\n",
            "Epoch [9/10], Loss: 0.4204, Accuracy: 85.70%\n",
            "Epoch [10/10], Loss: 0.4030, Accuracy: 86.14%\n",
            "Test Loss: 0.4749, Test Accuracy: 83.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"./cifar10_resnet18.pth\")\n",
        "\n",
        "artifact = wandb.Artifact(\"cifar10_model\", type=\"model\")\n",
        "artifact.add_file(\"./cifar10_resnet18.pth\")\n",
        "wandb.log_artifact(artifact)\n",
        "\n",
        "# Завершаем сессию wandb\n",
        "# wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwO1kkOfBmot",
        "outputId": "3d381fd1-4a6b-49ef-dba3-d1bcfc1b6a23"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Artifact cifar10_model>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "обучал на а100 в колабе про, боже храни такую дешёвую подписку на а100"
      ],
      "metadata": {
        "id": "VKWGbLe8CjeM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. **Модель: ResNet18**\n",
        "   - **Почему ResNet18?**  \n",
        "     ResNet18 — маленькая и производительная модель с остаточными соединениями, которые предотвращают проблему исчезающих градиентов\n",
        "   - **Предобученная модель:**  \n",
        "        Использую ImageNet так как она улучшает обучение и качество, потому что есть заранее извлечённые признаки\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### 2. **Размеры входа:**\n",
        "   - **Почему 32x32?**  \n",
        "     Выбор аугментаций и преобразований для модели основывается на сохранении 32 х 32  размера из CIFAR-10\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **Гиперпараметры обучения:**\n",
        "   - **Batch size: 64**\n",
        "     - так карта легла\n",
        "   - **Num epochs: 10**\n",
        "     - CIFAR-10 — небольшой датасет, поэтому 10 достаточно. Когда будем файн-тюнить на своём датасете, то может поменяться\n",
        "   - **Learning rate: 0.001**\n",
        "     - Дефолт для оптимизатора Adam, хорошо подходит для предобученных моделей. Если fine-tuning выполняется на новом датасете, скорость обучения можно попробовать уменьшить до \\(10^{-4}\\) или \\(10^{-5}\\) для более осторожной подстройки.\n",
        "\n",
        "---\n",
        "\n",
        "### 4. **Аугментации (data augmentations):**\n",
        "   - **RandomHorizontalFlip:**  \n",
        "     Подходит для CIFAR-10, так как многие изображения (например, собаки, кошки) симметричны и горизонтальная симметрия не изменяет смысл. Аналогично для одежды\n",
        "   - **RandomCrop (с padding=4):**  \n",
        "     Имитирует небольшие вариации в расположении объектов на изображении, что повышает устойчивость модели. Можно попробовать увеличить этот параметр\n",
        "\n",
        "---\n",
        "\n",
        "### 5. **Loss Function: CrossEntropyLoss**\n",
        "   - Используется из-за интерпретации предсказаний модели как вероятностей.\n",
        "\n",
        "---\n",
        "\n",
        "### 6. **Оптимизатор: Adam**\n",
        "   - Adam — устойчивый и быстро сходящийся оптимизатор с небольшим кол-во параметров при файнтюнинге\n",
        "\n",
        "---\n",
        "\n",
        "### 7. **Scheduler: Cosine Annealing**\n",
        "   - **Почему?**  \n",
        "     Этот scheduler плавно уменьшает learning rate, что помогает модели находить оптимальные веса ближе к концу обучения. Warm-up на начальных этапах ускоряет обучение, позволяя модели быстрее сходиться.\n",
        "\n",
        "---\n",
        "\n",
        "<!-- ### 8. **Fine-tuning на новом датасете:**\n",
        "   - **Замена выходного слоя:**  \n",
        "     Выходной слой ResNet18 заменяется, чтобы адаптировать модель под количество классов нового датасета.\n",
        "   - **Сохранение предобученных весов:**  \n",
        "     Замораживание начальных слоев позволяет сохранить общие признаки (например, края и текстуры) и сфокусировать обучение на высокоуровневых признаках нового датасета. -->\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Mfyxei15CIR1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: fine-tuning на датасете fashion"
      ],
      "metadata": {
        "id": "u9sLB0qT3nPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ### load dataset\n",
        "\n",
        "# new_transform = transforms.Compose([\n",
        "#     transforms.Resize((32, 32)),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "# ])\n",
        "\n",
        "# new_dataset = datasets.ImageFolder(root='./new_data', transform=new_transform)\n",
        "# new_loader = DataLoader(new_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# # Загрузка предобученной модели\n",
        "# model.fc = nn.Linear(model.fc.in_features, len(new_dataset.classes))\n",
        "# model = model.to(device)\n",
        "# model.load_state_dict(torch.load('./models/fashion_meter_cifar10.pth'))\n",
        "\n",
        "# # Fine-tuning\n",
        "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# train_model(model, new_loader, optimizer, criterion, num_epochs)\n",
        "\n",
        "# # Сохранение дообученной модели\n",
        "# torch.save(model.state_dict(), './models/fashion_meter_finetuned.pth')"
      ],
      "metadata": {
        "id": "QziTj4I63rKS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}